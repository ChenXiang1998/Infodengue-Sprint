{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6CXJ0gpHCcei",
    "outputId": "c3afccb5-7fd1-4461-cec6-da43a6df9ff1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 9s 14ms/step - loss: 0.0301\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0236\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0232\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0220\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0216\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0213\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0212\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0217\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0208\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0203\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0205\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0201\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0198\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0192\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0198\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0206\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0197\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0192\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0195\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0189\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0192\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0194\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0195\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0183\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0188\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0187\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0182\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0180\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0198\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0184\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0181\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0175\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0178\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0190\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0186\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0169\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0176\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0176\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0176\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0173\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0163\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0179\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0178\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 6s 26ms/step - loss: 0.0323\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0259\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0237\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0227\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0226\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0215\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0220\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0213\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0214\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0215\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0202\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0201\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0200\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0201\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0198\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0202\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0190\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0196\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0190\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0190\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0194\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0190\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0184\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0188\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0184\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0188\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0185\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0179\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0183\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0181\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0198\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0181\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0181\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0166\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0168\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0173\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0191\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0181\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0167\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0174\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0161\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0172\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0169\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0158\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 6s 23ms/step - loss: 0.0306\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0234\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0230\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0224\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0220\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0214\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0212\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0215\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0204\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0203\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0199\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0207\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0202\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0198\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0205\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0197\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0200\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0192\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0187\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0190\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0196\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0187\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0193\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0189\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0199\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0181\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0184\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0181\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0182\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0182\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0185\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0174\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0178\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0181\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0176\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0180\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0178\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0178\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0175\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0172\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0166\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0166\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0175\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0169\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0188\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0163\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0172\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0183\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0162\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0169\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0163\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0170\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0161\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0158\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0154\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0159\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0160\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0161\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0155\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0158\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0158\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0156\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0154\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0151\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0158\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0156\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0153\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0156\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0146\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0150\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0146\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0141\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0148\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.0154\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0151\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0147\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0148\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0152\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0137\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0133\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0138\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0152\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0142\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0142\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0131\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0131\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0133\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0143\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0140\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0126\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0143\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0133\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 6s 25ms/step - loss: 0.0356\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0258\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0237\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0224\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0231\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0214\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0218\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0213\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0216\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0212\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0208\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0206\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0198\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0196\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0200\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0194\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0211\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0190\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0195\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0185\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0182\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0191\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0200\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0185\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0177\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0183\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0190\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0174\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0184\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0187\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0180\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0183\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0179\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0170\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0174\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0183\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0175\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0177\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0168\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0171\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0168\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0178\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0175\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0163\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0164\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0166\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0159\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0166\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0174\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0163\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0168\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0158\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0159\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0157\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0160\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0150\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0161\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0155\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0148\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0152\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0146\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0142\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0148\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0146\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0148\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0153\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0148\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0147\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0161\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0145\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0138\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0139\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0138\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0134\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0139\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0141\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0141\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0146\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0139\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0135\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0137\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0131\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0130\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 6s 13ms/step - loss: 0.0301\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0238\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0224\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0224\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0226\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0218\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0211\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0208\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0205\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0202\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0208\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0205\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0201\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0202\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0207\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0195\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0206\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0199\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0196\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0185\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0192\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0178\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0191\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0184\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0185\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0184\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0194\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0188\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0186\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0178\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0182\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0182\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0183\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0180\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.0175\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0164\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0178\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0177\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0186\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0189\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0175\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0191\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0190\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0172\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0180\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0166\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0172\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0164\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0159\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0172\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0163\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0168\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0168\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0157\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0170\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0156\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0156\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0161\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0158\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0161\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0155\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0151\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0154\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0156\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0159\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0149\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0147\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0134\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0151\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0142\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0150\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0147\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0140\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0141\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0133\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0131\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0133\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0145\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0146\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0141\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0159\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0143\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0137\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0141\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0139\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0127\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0126\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0116\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0133\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0126\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0131\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0130\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0123\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0122\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0125\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0126\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0121\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0122\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0119\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0117\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0108\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0127\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0117\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0118\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0124\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0124\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0119\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.0126\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0108\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0118\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0121\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0109\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0113\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0112\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0110\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0108\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0106\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0109\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0118\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0109\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0112\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0118\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0103\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0105\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0108\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0108\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0103\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0110\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0105\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.0103\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0109\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0104\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0098\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0094\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0090\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0098\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0098\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0093\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0104\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0097\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0124\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0101\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0103\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0100\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0105\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0094\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0094\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0095\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0098\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0106\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0096\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0091\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0089\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0102\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0091\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0090\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0089\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0087\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0102\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0092\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0102\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0094\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0081\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0095\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0083\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0087\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0092\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0088\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0092\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0092\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0083\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0088\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0097\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0094\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0098\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0086\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0093\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0086\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0090\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0086\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0087\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0081\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0083\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0078\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0077\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0079\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0078\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0070\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0086\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0081\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1fbc561090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 5s 15ms/step - loss: 0.0351\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0263\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0242\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0226\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0221\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0219\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0215\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0208\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0211\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0206\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0209\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0202\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0216\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0209\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0202\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0201\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0193\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0195\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0200\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0189\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0199\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0183\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0191\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0186\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0196\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0188\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0179\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0182\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0186\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0174\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0174\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0172\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0179\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0165\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0193\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0184\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0162\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0185\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0178\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0172\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0172\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0169\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0169\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0170\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0173\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0162\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0166\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0172\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0160\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0164\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0165\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0173\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0159\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0155\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0158\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0158\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0153\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0156\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0152\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0147\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0161\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0155\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0153\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0154\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0158\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0147\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0149\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0153\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0158\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0154\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0149\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0152\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0144\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0142\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0142\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0148\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0163\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0156\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0142\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0143\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0135\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0142\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0142\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0133\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0146\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0142\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0137\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0136\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0132\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0131\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0129\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0130\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0120\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0125\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0125\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0121\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0131\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0136\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0117\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0125\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0132\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0140\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0124\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0129\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0122\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0115\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0127\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0120\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0110\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0130\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0129\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0119\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0111\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0123\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0125\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0109\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0113\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0121\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0111\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0120\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0109\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0107\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0110\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0109\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0110\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0104\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0105\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0105\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0109\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0108\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0112\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0109\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0102\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0099\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0108\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0097\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0093\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0100\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0097\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0105\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0099\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0102\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0096\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0089\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0093\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0098\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0099\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0104\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0105\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0086\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0090\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0086\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0085\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0086\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0087\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0102\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0094\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0099\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0102\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0092\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0093\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0091\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0095\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0096\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0084\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0084\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0086\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0081\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0096\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0096\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0079\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0091\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0089\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0089\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0087\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0080\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0078\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0075\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0083\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0081\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0087\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0083\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1fa47d3520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for ce task 1 with params: epochs=50, batch_size=32\n",
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 6s 15ms/step - loss: 0.0277\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0234\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0225\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0228\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0224\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0218\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0215\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0217\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0211\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0214\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0206\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0206\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0201\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0220\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0208\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0203\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0202\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0201\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0205\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0198\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0195\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0197\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0191\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0190\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0191\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0204\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0194\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0186\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0182\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0181\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0190\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0194\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0187\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0198\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0197\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0187\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0195\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0188\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0190\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0182\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0201\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0175\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0191\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0185\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0174\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 6s 25ms/step - loss: 0.0317\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0252\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0233\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0224\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0219\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0221\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0217\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0218\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0210\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0212\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0207\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0209\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0215\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0204\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0201\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0206\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0204\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0205\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0193\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0196\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0200\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0195\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0189\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0200\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0193\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0195\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0185\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0186\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0199\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0187\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0179\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0196\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0188\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0186\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0190\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0183\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0191\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0179\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0184\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0189\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0182\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0180\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "45/45 [==============================] - 7s 16ms/step - loss: 0.0288\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0231\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0223\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0229\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0221\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0216\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0215\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0216\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0215\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0212\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0209\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0209\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0209\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0204\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0206\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0200\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0207\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0200\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0202\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0202\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0195\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0194\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0199\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0188\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0200\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0195\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0183\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0195\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0198\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0183\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0181\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0188\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0185\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0188\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0192\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.0187\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0190\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0191\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0185\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0186\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0179\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0177\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0190\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0181\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0176\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0177\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0178\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0187\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0182\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0171\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0171\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0172\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0175\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0168\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0168\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0166\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0168\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0170\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0168\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0165\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0169\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0182\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0159\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0166\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0160\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0166\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0162\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0162\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0165\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0157\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.0183\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0161\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0168\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0163\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0152\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0162\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0160\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0156\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0143\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0159\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0143\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0146\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0150\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0154\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0148\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0144\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0135\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.0132\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0145\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0151\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0133\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0134\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0133\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0129\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0134\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 6s 23ms/step - loss: 0.0326\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0246\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0233\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0236\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0227\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0219\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0221\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0218\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0213\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0213\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0212\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0211\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0213\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0206\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0210\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0202\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0203\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0203\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0198\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0195\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0196\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0189\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0189\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0206\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0206\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0198\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0198\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0197\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0193\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0184\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0192\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0187\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0178\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0187\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0192\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0193\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0191\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0182\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0173\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0188\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0187\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0175\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0179\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0185\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0180\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0175\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0171\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0174\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0179\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0174\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0170\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0188\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0172\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0175\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0168\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0160\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0170\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0166\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0164\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0158\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0167\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0173\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0168\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0160\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0167\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0153\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0154\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0156\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0168\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0157\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0163\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0165\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0154\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0155\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0159\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0155\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0150\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0169\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0153\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0147\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0148\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0160\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0163\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0145\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0149\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0152\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0137\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0144\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0140\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0133\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 6s 14ms/step - loss: 0.0285\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0232\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0234\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0215\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0219\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0217\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0215\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0216\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0215\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0211\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0208\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0209\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0211\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0203\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0203\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0208\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0206\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0197\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0199\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0196\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0202\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0193\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0219\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0198\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0196\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.0203\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0190\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0187\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0194\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0201\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0188\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0181\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0185\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0183\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0188\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0193\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0189\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0180\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0188\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0173\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0203\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0192\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0196\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0189\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0188\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.0184\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0187\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0186\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0181\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0190\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0176\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0181\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0186\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0184\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0180\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0171\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0172\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0174\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0178\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0171\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0178\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0179\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0163\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0161\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0174\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0174\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0178\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0165\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0175\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0173\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0159\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0162\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0158\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0159\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0164\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0152\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0166\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0164\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0159\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0158\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0154\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0158\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0162\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0167\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0157\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0147\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0156\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0172\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0153\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0156\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0142\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0152\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0158\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0139\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0141\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0149\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0153\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0147\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0147\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0141\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0139\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0139\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0139\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0136\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0140\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0140\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0147\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0147\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0128\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0141\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0134\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0137\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0129\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0140\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0145\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.0130\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0129\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0140\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0123\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0137\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0126\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0143\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0138\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0136\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0127\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0125\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0124\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0122\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0126\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0124\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0122\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0115\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0115\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0113\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0130\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0118\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0132\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0119\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0103\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0114\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0111\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0112\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0115\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0110\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0117\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0108\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0104\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0107\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 1s 24ms/step - loss: 0.0107\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0109\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.0101\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0100\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0110\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0107\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0110\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0104\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0096\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0109\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0096\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0098\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0107\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0114\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0098\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0102\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0101\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.0095\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0092\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0094\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0099\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0105\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0096\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0096\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0092\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0103\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0085\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0109\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0120\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0107\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0086\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0099\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0085\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0086\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0085\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0086\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 0.0109\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.0104\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0098\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0077\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0090\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0095\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0097\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0088\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0087\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0095\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0081\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.0077\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0084\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0082\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0084\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 5s 14ms/step - loss: 0.0321\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0241\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0232\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0223\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0231\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0221\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0220\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0213\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0212\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0212\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0202\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0209\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0218\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0207\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0202\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0206\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0201\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0198\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0195\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0194\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0199\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0197\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0189\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0183\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0199\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0194\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0197\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0199\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0193\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0192\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0190\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0185\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0179\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0192\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0182\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0187\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0186\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0194\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0186\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0182\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0182\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0186\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0181\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0175\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0178\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0176\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0171\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0170\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0173\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0175\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0173\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0175\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0175\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0175\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0172\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0161\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0181\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0167\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0172\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0153\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0161\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0160\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0156\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0164\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0156\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0162\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0156\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0158\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0150\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0161\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0176\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0152\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0158\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0164\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0152\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0154\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0144\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0147\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0146\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0150\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0152\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0145\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0148\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0154\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0136\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0138\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0133\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0131\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0142\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0132\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0147\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0132\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0120\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0137\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0134\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0128\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0121\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0129\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0120\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0123\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0128\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0133\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0125\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0115\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0114\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.0122\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0121\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0112\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0119\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.0134\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.0120\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0117\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0113\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0129\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0110\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0106\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0107\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0115\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0108\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0107\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0118\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0099\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0106\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0119\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0103\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0099\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0103\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0099\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0105\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0101\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0086\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0098\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0101\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0098\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0088\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.0102\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0097\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0097\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.0103\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.0093\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.0093\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0097\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0089\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0086\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0085\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0088\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0096\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0095\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0085\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0090\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0097\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0082\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0086\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0092\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0091\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0099\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0088\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0091\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0095\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0080\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0095\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0097\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0078\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0095\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0092\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0092\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0087\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0090\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.0076\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0073\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.0089\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0085\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0089\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0094\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0082\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0089\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.0081\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for ce task 2 with params: epochs=50, batch_size=32\n",
      "GO - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 7s 24ms/step - loss: 0.0541\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0394\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0346\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0348\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0357\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0342\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0345\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0347\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0338\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0328\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0333\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0320\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0331\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0321\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0313\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0325\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0324\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0321\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0317\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0317\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0312\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0319\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0297\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0321\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0320\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0304\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0312\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0317\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0313\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0305\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0312\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0303\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0301\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0298\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0306\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0297\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0314\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0304\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0300\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0293\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0300\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0300\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0293\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0304\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0289\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0296\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0292\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 5s 15ms/step - loss: 0.0569\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0423\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0362\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0356\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0347\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0338\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0352\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0338\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0338\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0328\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0329\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0336\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0332\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0321\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0331\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0323\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0335\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0320\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0324\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0316\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0306\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0317\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0332\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0318\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0318\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0316\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0315\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0306\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0324\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0320\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0305\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0304\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0313\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0316\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0299\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0301\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0297\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0300\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0294\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0295\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0309\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0307\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0298\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0294\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0296\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0292\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0294\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0291\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0293\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 6s 14ms/step - loss: 0.0520\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0373\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0362\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0359\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0354\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0360\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0348\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0342\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0332\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0337\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0336\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0334\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0318\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0333\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0323\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0330\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0316\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0320\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0313\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0313\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0310\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0318\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0314\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0308\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0302\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0316\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0315\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0303\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0305\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0310\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0299\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0317\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0293\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0302\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0297\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0298\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0301\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0299\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0293\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0302\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0292\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0305\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0299\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0295\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0292\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0289\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0286\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0286\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0290\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0289\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0292\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0296\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0306\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0300\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0289\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0300\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0291\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0294\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0281\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0285\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0283\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0285\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0294\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0286\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0285\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0294\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0286\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0288\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0273\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0272\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0287\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0276\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0291\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0283\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0278\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0276\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0265\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0267\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0279\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0274\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0291\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0287\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0269\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0279\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0271\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0273\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0269\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0270\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0271\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0276\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0269\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0267\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0271\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0272\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 5s 15ms/step - loss: 0.0632\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0431\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0362\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0357\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0358\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0335\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0348\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0337\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0352\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0346\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0347\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0331\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0341\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0331\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0324\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0321\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0322\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0311\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0318\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0304\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0309\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0315\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0318\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0312\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0311\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0310\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0303\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0304\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0309\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0318\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0314\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0307\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0313\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0299\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0302\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0303\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0310\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0318\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0299\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0291\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0299\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0304\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0311\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0301\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0296\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0293\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0291\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0300\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0297\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0290\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0291\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0292\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0293\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0301\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0291\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0286\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0295\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0290\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0287\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0287\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0289\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0288\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0287\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0294\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0286\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0291\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0293\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0286\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0287\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0287\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0284\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0276\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0283\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0296\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0278\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0282\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0285\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0284\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0275\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0279\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0279\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0282\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0277\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 1s 23ms/step - loss: 0.0288\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0277\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0288\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0287\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0277\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0276\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0286\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0276\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0272\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0273\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0279\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0272\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0271\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0268\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0281\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0283\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c0d697b98a8b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-1-c0d697b98a8b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 6s 14ms/step - loss: 0.0523\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0379\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0356\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0362\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0339\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0343\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0342\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0331\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0332\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0345\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0331\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0333\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0325\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0323\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0324\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0310\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0327\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0320\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0313\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0311\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0313\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0310\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0318\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0314\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0307\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0315\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0310\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0324\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0315\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0298\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0311\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0300\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0295\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0304\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0299\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0295\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0295\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0302\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0298\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0295\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0302\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0304\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0293\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0286\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0306\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0304\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0307\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0296\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0294\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0292\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0295\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0289\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0300\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0297\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0296\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0305\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0282\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0290\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0288\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0294\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0288\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0293\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0285\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0291\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0292\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0290\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0291\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0281\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0278\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0293\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0280\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0279\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0291\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0283\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0282\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0273\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0292\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0276\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0269\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0286\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0281\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0284\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0275\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0273\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0289\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0281\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0293\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0280\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0285\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.0281\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0273\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0280\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0280\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0275\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0268\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0280\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0273\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0271\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0276\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0271\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0279\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0271\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0271\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0274\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0272\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0266\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0268\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0263\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0280\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0278\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0264\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0267\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0266\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0259\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0263\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0276\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0273\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0258\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0274\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0261\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0272\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0263\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0276\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0272\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0260\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0258\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0259\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0261\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0277\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0262\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0266\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0266\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0266\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0263\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0256\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0260\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0267\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0265\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0255\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0248\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0267\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0252\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0250\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0259\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0258\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0259\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0258\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.0255\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0266\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0260\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0251\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0259\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0254\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0263\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0269\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0273\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0248\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0245\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0247\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0244\n",
      "Epoch 164/200\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.0258"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0d697b98a8b>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_size_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mmape1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclimate_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdengue_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmape1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_mape_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mbest_mape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmape1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c0d697b98a8b>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(state, climate_file, dengue_file, train_col, target_col, epochs, batch_size)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "import os\n",
    "\n",
    "# List of states and their corresponding file paths\n",
    "states = ['ce', 'go', 'mg', 'pr']\n",
    "climate_files = [f'aggregated_climate_data_{state}.csv' for state in states]\n",
    "dengue_files = [f'aggregated_dengue_data_{state}.csv' for state in states]\n",
    "\n",
    "# Function to preprocess data, train model, and return MAPE and results DataFrame\n",
    "def train_and_evaluate(state, climate_file, dengue_file, train_col, target_col, epochs, batch_size):\n",
    "    # Load data\n",
    "    dengue_data = pd.read_csv(dengue_file)\n",
    "    climate_data = pd.read_csv(climate_file)\n",
    "\n",
    "    # Filter for train and target columns\n",
    "    dengue_data[train_col] = dengue_data[train_col].astype(bool)\n",
    "    dengue_data[target_col] = dengue_data[target_col].astype(bool)\n",
    "\n",
    "    dengue_train = dengue_data[dengue_data[train_col]]\n",
    "    dengue_target = dengue_data[dengue_data[target_col]]\n",
    "\n",
    "    # Convert date columns to datetime\n",
    "    dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "    dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "    climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "    # Merge the datasets on 'date'\n",
    "    train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "    target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "    # Select relevant columns excluding 'epiweek'\n",
    "    columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                       'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                       'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                       'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                       'thermal_range', 'rainy_days']\n",
    "\n",
    "    train_data = train_data[columns_to_keep]\n",
    "    target_data = target_data[columns_to_keep]\n",
    "\n",
    "    # Apply Variance Threshold\n",
    "    climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "    selector = VarianceThreshold(threshold=0.1)\n",
    "    selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "    # Get the selected feature names\n",
    "    selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "    selected_feature_names = list(selected_feature_names)\n",
    "    print(f\"{state.upper()} - Selected Features:\", selected_feature_names)\n",
    "\n",
    "    # Add 'casos' and 'date' to the selected features\n",
    "    selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "    # Update train_data and target_data with selected features\n",
    "    train_data = train_data[selected_feature_names]\n",
    "    target_data = target_data[selected_feature_names]\n",
    "\n",
    "    # Separate the target variable and climate features excluding 'date'\n",
    "    X_train_climate = train_data.drop(columns=['casos', 'date'])\n",
    "    X_target_climate = target_data.drop(columns=['casos', 'date'])\n",
    "\n",
    "    # Standardize the climate features\n",
    "    scaler_climate = StandardScaler()\n",
    "    X_train_climate_scaled = scaler_climate.fit_transform(X_train_climate)\n",
    "    X_target_climate_scaled = scaler_climate.transform(X_target_climate)\n",
    "\n",
    "    # Scale the 'casos' column separately\n",
    "    scaler_casos = MinMaxScaler()\n",
    "    train_data['casos_scaled'] = scaler_casos.fit_transform(train_data[['casos']])\n",
    "    target_data['casos_scaled'] = scaler_casos.transform(target_data[['casos']])\n",
    "\n",
    "    # Apply PCA to climate features\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_climate_scaled)\n",
    "    X_target_pca = pca.transform(X_target_climate_scaled)\n",
    "\n",
    "    # Create DataFrames with PCA components\n",
    "    n_components = X_train_pca.shape[1]\n",
    "    train_pca_df = pd.DataFrame(X_train_pca, index=train_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "    target_pca_df = pd.DataFrame(X_target_pca, index=target_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "    # Add the scaled target variable 'casos_scaled' and 'date' to the PCA DataFrames\n",
    "    train_pca_df['casos_scaled'] = train_data['casos_scaled']\n",
    "    train_pca_df['date'] = train_data['date']\n",
    "    target_pca_df['casos_scaled'] = target_data['casos_scaled']\n",
    "    target_pca_df['date'] = target_data['date']\n",
    "\n",
    "    # Set date as index\n",
    "    train_pca_df.set_index('date', inplace=True)\n",
    "    target_pca_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Prepare the data for LSTM\n",
    "    X_train = train_pca_df.drop(columns=['casos_scaled']).values\n",
    "    y_train = train_pca_df['casos_scaled'].values\n",
    "    X_target = target_pca_df.drop(columns=['casos_scaled']).values\n",
    "\n",
    "    # Define a more complex LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(1000, activation='relu', return_sequences=True, input_shape=(1, X_train.shape[1])))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(500, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(250, activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(100, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Reshape the data for LSTM\n",
    "    X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_target_reshaped = X_target.reshape((X_target.shape[0], 1, X_target.shape[1]))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_reshaped, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'model_{state}_{train_col}.h5')\n",
    "\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_target_reshaped)\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    y_pred_inv = scaler_casos.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Set values less than 0 to 0\n",
    "    y_pred_inv[y_pred_inv < 0] = 0\n",
    "    # Convert the predictions to integers\n",
    "    y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "    # Inverse transform the actual values\n",
    "    y_target_inv = scaler_casos.inverse_transform(target_data['casos_scaled'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Calculate MAE and MAPE\n",
    "    mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "    mape = mean_absolute_percentage_error(y_target_inv, y_pred_inv) * 100\n",
    "\n",
    "    # Create a DataFrame with the date, real cases, and predicted cases\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': target_pca_df.index,\n",
    "        'real': y_target_inv,\n",
    "        'predict': y_pred_inv\n",
    "    })\n",
    "\n",
    "    return mape, results_df\n",
    "\n",
    "# Define the grid search parameters\n",
    "epochs_list = [50, 100, 200]\n",
    "batch_size_list = [16, 32]\n",
    "\n",
    "# Loop through each state and each task, and perform grid search for the best LSTM parameters\n",
    "for state, climate_file, dengue_file in zip(states, climate_files, dengue_files):\n",
    "    best_mape_1 = float('inf')\n",
    "    best_results_df_1 = None\n",
    "    best_params_1 = None\n",
    "\n",
    "    best_mape_2 = float('inf')\n",
    "    best_results_df_2 = None\n",
    "    best_params_2 = None\n",
    "\n",
    "    # First task: Filter for train_1 == True and target_1 ==target_1 == True\n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            mape1, results_df1 = train_and_evaluate(state, climate_file, dengue_file, 'train_1', 'target_1', epochs, batch_size)\n",
    "            if mape1 < best_mape_1:\n",
    "                best_mape_1 = mape1\n",
    "                best_results_df_1 = results_df1\n",
    "                best_params_1 = (epochs, batch_size)\n",
    "\n",
    "    best_results_df_1.to_csv(f'{state}_1.csv', index=False)\n",
    "    print(f\"Results saved for {state} task 1 with params: epochs={best_params_1[0]}, batch_size={best_params_1[1]}\")\n",
    "\n",
    "    # Second task: Filter for train_2 == True and target_2 == True\n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            mape2, results_df2 = train_and_evaluate(state, climate_file, dengue_file, 'train_2', 'target_2', epochs, batch_size)\n",
    "            if mape2 < best_mape_2:\n",
    "                best_mape_2 = mape2\n",
    "                best_results_df_2 = results_df2\n",
    "                best_params_2 = (epochs, batch_size)\n",
    "\n",
    "    best_results_df_2.to_csv(f'{state}_2.csv', index=False)\n",
    "    print(f\"Results saved for {state} task 2 with params: epochs={best_params_2[0]}, batch_size={best_params_2[1]}\")\n",
    "\n",
    "print(\"Model training and evaluation completed for all states and tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hd62xLkcIjGW",
    "outputId": "449809f2-f679-4d55-c947-54552d89a17e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e42ada829560>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-4-e42ada829560>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 6s 16ms/step - loss: 0.0344\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0259\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0242\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0226\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0220\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0227\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0215\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0211\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0212\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0211\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0209\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0207\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0204\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0212\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0203\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0200\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0200\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0190\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0195\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0203\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0205\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0195\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0187\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0178\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0193\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0185\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0194\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0188\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0191\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0188\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0190\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0188\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0180\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0191\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0183\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0180\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0172\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0169\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0176\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0170\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0179\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0180\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0168\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0164\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0160\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0164\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0165\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0160\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0161\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0167\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0171\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0164\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0158\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0172\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0167\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0167\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0164\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0153\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0171\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0151\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0165\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0157\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0146\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0170\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0160\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0155\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0153\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0154\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0145\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0142\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0147\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0158\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0142\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0152\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0145\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0153\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0146\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0152\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0147\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0145\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0147\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0144\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0147\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0143\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0137\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0137\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0146\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0144\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0151\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0144\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0139\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0133\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0143\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0136\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0143\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0133\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0137\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0133\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0139\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0138\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0133\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0133\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0124\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0142\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0139\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0127\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0127\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0128\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0120\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0129\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0136\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0146\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0123\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0123\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0123\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0123\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0119\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0120\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0124\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0119\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0117\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0114\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0109\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0118\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0111\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0114\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0113\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0102\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0106\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0108\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0117\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0102\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0105\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0115\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0125\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0111\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0102\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0123\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0111\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0107\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0105\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0099\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0099\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0109\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0094\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0092\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0094\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0106\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0105\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0103\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0097\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0105\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0102\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0104\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0090\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0094\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0102\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0110\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0097\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0098\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0090\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0086\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0094\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0086\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0088\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0091\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0085\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0084\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0086\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0100\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0086\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0098\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0090\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0089\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0084\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0078\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0077\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0081\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0094\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0086\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0083\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0080\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0078\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0080\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0084\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0087\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0086\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0081\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0078\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0077\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0077\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0078\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0076\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0075\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0071\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0085\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0068\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0070\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0067\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0070\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0076\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0086\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0067\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0067\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0070\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0075\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0073\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0065\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0079\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0072\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0077\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0075\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0083\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0075\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0078\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0066\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0076\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0074\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0074\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0069\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0068\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0068\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0072\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0071\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0067\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0067\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0068\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0069\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0082\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0076\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0060\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0064\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0063\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0070\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0065\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0072\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0066\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0061\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0065\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0072\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0062\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0069\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0069\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0098\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0069\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0067\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0069\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0068\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0068\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0069\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0060\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0062\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0065\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0067\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0076\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0071\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0069\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0063\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0062\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0064\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0056\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0063\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0067\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0059\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0059\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0064\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0059\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0057\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0056\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0061\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0056\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0058\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0055\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0062\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0060\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0075\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0058\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0062\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0063\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0065\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0061\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0057\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0058\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0047\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0058\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0071\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0066\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0060\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0059\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0057\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0052\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0051\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0053\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0049\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0061\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0053\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0067\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0070\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0064\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0060\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0065\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0055\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0050\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0047\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0055\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0057\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0068\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0064\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0062\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0053\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0052\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0053\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0047\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0052\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0053\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.0055\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0061\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0058\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0063\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0055\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0047\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0054\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0050\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0054\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0044\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0045\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0052\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0051\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0064\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0061\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0060\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0051\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0049\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0050\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0043\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0053\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0049\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0064\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0044\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0045\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0046\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0048\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0044\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0042\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0048\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0050\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0042\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0045\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0048\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0044\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0040\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0059\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0059\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0053\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0067\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0066\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0078\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0065\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0053\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0060\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0055\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0062\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0047\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0057\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0047\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0054\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0041\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0045\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0045\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0051\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0052\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0046\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0054\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0039\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0047\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0050\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0050\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0046\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0043\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0033\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0071\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0055\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0057\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0049\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0048\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0060\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0048\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0038\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0043\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0041\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0045\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0036\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0036\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 0.0049\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0046\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0056\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0061\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0052\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0060\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0055\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0053\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0057\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0060\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0049\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0046\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0049\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0048\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0049\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0058\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0049\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0053\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0051\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0055\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0044\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0048\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0047\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0045\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0044\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0043\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0044\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0046\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0040\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0051\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0037\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0056\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0061\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0045\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0044\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0039\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0039\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0038\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0048\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0051\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0046\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0054\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0041\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0038\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0051\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0045\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0038\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0040\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0040\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0036\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0059\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0047\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0045\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0039\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0050\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0054\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0051\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0053\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0041\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0043\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0033\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 0.0032\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0043\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 0.0046\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "Real Cases (Actual): [216. 186. 132. 133. 165. 161. 143. 142. 106.  74.  47.  65. 163. 127.\n",
      " 170. 226. 240. 246. 274. 354. 482. 577. 561. 614. 581. 444. 543. 509.\n",
      " 476. 636. 689. 666. 615. 512. 475. 514. 424. 362. 340. 339. 291. 253.\n",
      " 272. 216. 210. 224. 188. 134. 133. 104.  88.]\n",
      "Real Cases (Predicted): [ 418  418  295 1683 1086 4737 2694 1021  396  382 4602 5022 1437  480\n",
      " 1152 1801 1848 4790 1988  900 2240 1363  549 4098 3376 3845 1966 4984\n",
      "  953 2715 2671  812 1921 1822 2132  785 1015 1556 1575  328  620  619\n",
      "  378  780  657  324  300  418  405  392  418]\n",
      "Mean Absolute Error (MAE): 1321.0\n",
      "Mean Absolute Percentage Error (MAPE): 760.651178804038%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# List of states and their corresponding file paths\n",
    "#states = ['ce', 'go', 'mg', 'pr']\n",
    "#climate_files = [f'aggregated_climate_data_{state}.csv' for state in states]\n",
    "#dengue_files = [f'aggregated_dengue_data_{state}.csv' for state in states]\n",
    "\n",
    "# Load data\n",
    "dengue_file_path = 'aggregated_dengue_data_ce.csv'\n",
    "climate_file_path = 'aggregated_climate_data_ce.csv'\n",
    "dengue_data = pd.read_csv(dengue_file_path)\n",
    "climate_data = pd.read_csv(climate_file_path)\n",
    "\n",
    "# Filter for train_1 == True and target_1 == True\n",
    "dengue_data['train_1'] = dengue_data['train_1'].astype(bool)\n",
    "dengue_data['target_1'] = dengue_data['target_1'].astype(bool)\n",
    "\n",
    "dengue_train = dengue_data[dengue_data['train_1']]\n",
    "dengue_target = dengue_data[dengue_data['target_1']]\n",
    "\n",
    "# Convert date columns to datetime\n",
    "dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "# Merge the datasets on 'date'\n",
    "train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "# Select relevant columns excluding 'epiweek'\n",
    "columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                   'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                   'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                   'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                   'thermal_range', 'rainy_days']\n",
    "\n",
    "train_data = train_data[columns_to_keep]\n",
    "target_data = target_data[columns_to_keep]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "selected_feature_names = list(selected_feature_names)\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "# Add 'casos' and 'date' to the selected features\n",
    "selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "# Update train_data and target_data with selected features\n",
    "train_data = train_data[selected_feature_names]\n",
    "target_data = target_data[selected_feature_names]\n",
    "\n",
    "# Separate the target variable and climate features excluding 'date'\n",
    "X_train_climate = train_data.drop(columns=['casos', 'date'])\n",
    "X_target_climate = target_data.drop(columns=['casos', 'date'])\n",
    "\n",
    "# Standardize the climate features\n",
    "scaler_climate = StandardScaler()\n",
    "X_train_climate_scaled = scaler_climate.fit_transform(X_train_climate)\n",
    "X_target_climate_scaled = scaler_climate.transform(X_target_climate)\n",
    "\n",
    "# Scale the 'casos' column separately\n",
    "scaler_casos = MinMaxScaler()\n",
    "train_data['casos_scaled'] = scaler_casos.fit_transform(train_data[['casos']])\n",
    "target_data['casos_scaled'] = scaler_casos.transform(target_data[['casos']])\n",
    "\n",
    "# Apply PCA to climate features\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_climate_scaled)\n",
    "X_target_pca = pca.transform(X_target_climate_scaled)\n",
    "\n",
    "# Create DataFrames with PCA components\n",
    "n_components = X_train_pca.shape[1]\n",
    "train_pca_df = pd.DataFrame(X_train_pca, index=train_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "target_pca_df = pd.DataFrame(X_target_pca, index=target_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Add the scaled target variable 'casos_scaled' and 'date' to the PCA DataFrames\n",
    "train_pca_df['casos_scaled'] = train_data['casos_scaled']\n",
    "train_pca_df['date'] = train_data['date']\n",
    "target_pca_df['casos_scaled'] = target_data['casos_scaled']\n",
    "target_pca_df['date'] = target_data['date']\n",
    "\n",
    "# Set date as index\n",
    "train_pca_df.set_index('date', inplace=True)\n",
    "target_pca_df.set_index('date', inplace=True)\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "X_train = train_pca_df.drop(columns=['casos_scaled']).values\n",
    "y_train = train_pca_df['casos_scaled'].values\n",
    "X_target = target_pca_df.drop(columns=['casos_scaled']).values\n",
    "\n",
    "\n",
    "# Define a more complex LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000, activation='relu', return_sequences=True, input_shape=(1, X_train.shape[1])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(500, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(250, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_target_reshaped = X_target.reshape((X_target.shape[0], 1, X_target.shape[1]))\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train_reshaped, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "model.fit(X_train_reshaped, y_train, epochs=500, batch_size=32,verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('model_ce_task1.h5')\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_target_reshaped)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_inv = scaler_casos.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Set values less than 0 to 0\n",
    "y_pred_inv[y_pred_inv < 0] = 0\n",
    "# Convert the predictions to integers\n",
    "y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "# Inverse transform the actual values\n",
    "y_target_inv = scaler_casos.inverse_transform(target_data['casos_scaled'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Print or return the real cases\n",
    "print(\"Real Cases (Actual):\", y_target_inv)\n",
    "print(\"Real Cases (Predicted):\", y_pred_inv)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "mape = np.mean(np.abs((y_target_inv - y_pred_inv) / y_target_inv)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0ogDfL1M25B",
    "outputId": "c90cdd23-afa5-4cca-99b3-abd3a5e22843"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9936cf8d64ed>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-6-9936cf8d64ed>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "WARNING:tensorflow:Layer lstm_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 7s 14ms/step - loss: 0.0077\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0074\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0074\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0071\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0071\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0069\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0071\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0069\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0068\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0068\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0068\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0067\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0067\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0067\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0067\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0069\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0068\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0067\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0066\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0065\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0071\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0067\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0066\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0065\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0064\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0065\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0069\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0066\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0067\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0064\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0065\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0064\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0065\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0069\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0062\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0065\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0066\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0066\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0064\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0063\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0063\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0065\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0066\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0066\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0059\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0062\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0063\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0068\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0067\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0067\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0065\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.0064\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0064\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0069\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0063\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0068\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0065\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0060\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0065\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0061\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0059\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0061\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0060\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0063\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0064\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0062\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.0058\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.0061\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0054\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0056\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0075\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0065\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0057\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0060\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0067\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.0060\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0062\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0057\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.0063\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.0062\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.0053\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0077\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0064\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0062\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0058\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0055\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0057\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0059\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.0055\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "Real Cases (Actual): [250. 196. 161. 147. 129. 117. 118. 110.  87.  52.  44.  81. 198. 195.\n",
      " 198. 214. 251. 277. 180. 148. 167. 143. 125. 119. 122. 125. 106. 153.\n",
      " 135. 143. 127. 131.  89.  65.  75.  69.  78.  90. 103. 115.  93.  89.\n",
      "  57.  46.  75.  65.  67.  77.  75.  73.  57.]\n",
      "Real Cases (Predicted): [172 359 218 149 165 202 207 255 210 203 358 225 245 413 285 260 699 294\n",
      " 303 259 361 257 434 179 311 353 245 249 264 304 200 269 252 187 218 198\n",
      " 179 167 170 171 168 177 169 163 162 142 159 128 154 161 148]\n",
      "Mean Absolute Error (MAE): 120.17647058823529\n",
      "Mean Absolute Percentage Error (MAPE): 122.31070528920984%\n",
      "Results saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# Load data\n",
    "dengue_file_path = 'aggregated_dengue_data_am.csv'\n",
    "climate_file_path = 'aggregated_climate_data_am.csv'\n",
    "dengue_data = pd.read_csv(dengue_file_path)\n",
    "climate_data = pd.read_csv(climate_file_path)\n",
    "\n",
    "# Filter for train_1 == True and target_1 == True\n",
    "dengue_data['train_1'] = dengue_data['train_1'].astype(bool)\n",
    "dengue_data['target_1'] = dengue_data['target_1'].astype(bool)\n",
    "\n",
    "dengue_train = dengue_data[dengue_data['train_1']]\n",
    "dengue_target = dengue_data[dengue_data['target_1']]\n",
    "\n",
    "# Convert date columns to datetime\n",
    "dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "# Merge the datasets on 'date'\n",
    "train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "# Select relevant columns excluding 'epiweek'\n",
    "columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                   'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                   'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                   'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                   'thermal_range', 'rainy_days']\n",
    "\n",
    "train_data = train_data[columns_to_keep]\n",
    "target_data = target_data[columns_to_keep]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "selected_feature_names = list(selected_feature_names)\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "# Add 'casos' and 'date' to the selected features\n",
    "selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "# Update train_data and target_data with selected features\n",
    "train_data = train_data[selected_feature_names]\n",
    "target_data = target_data[selected_feature_names]\n",
    "\n",
    "# Separate the target variable and climate features excluding 'date'\n",
    "X_train_climate = train_data.drop(columns=['casos', 'date'])\n",
    "X_target_climate = target_data.drop(columns=['casos', 'date'])\n",
    "\n",
    "# Standardize the climate features\n",
    "scaler_climate = StandardScaler()\n",
    "X_train_climate_scaled = scaler_climate.fit_transform(X_train_climate)\n",
    "X_target_climate_scaled = scaler_climate.transform(X_target_climate)\n",
    "\n",
    "# Scale the 'casos' column separately\n",
    "scaler_casos = MinMaxScaler()\n",
    "train_data['casos_scaled'] = scaler_casos.fit_transform(train_data[['casos']])\n",
    "target_data['casos_scaled'] = scaler_casos.transform(target_data[['casos']])\n",
    "\n",
    "# Apply PCA to climate features\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_climate_scaled)\n",
    "X_target_pca = pca.transform(X_target_climate_scaled)\n",
    "\n",
    "# Create DataFrames with PCA components\n",
    "n_components = X_train_pca.shape[1]\n",
    "train_pca_df = pd.DataFrame(X_train_pca, index=train_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "target_pca_df = pd.DataFrame(X_target_pca, index=target_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Add the scaled target variable 'casos_scaled' and 'date' to the PCA DataFrames\n",
    "train_pca_df['casos_scaled'] = train_data['casos_scaled']\n",
    "train_pca_df['date'] = train_data['date']\n",
    "target_pca_df['casos_scaled'] = target_data['casos_scaled']\n",
    "target_pca_df['date'] = target_data['date']\n",
    "\n",
    "# Set date as index\n",
    "train_pca_df.set_index('date', inplace=True)\n",
    "target_pca_df.set_index('date', inplace=True)\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "X_train = train_pca_df.drop(columns=['casos_scaled']).values\n",
    "y_train = train_pca_df['casos_scaled'].values\n",
    "X_target = target_pca_df.drop(columns=['casos_scaled']).values\n",
    "\n",
    "\n",
    "# Define a more complex LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000, activation='relu', return_sequences=True, input_shape=(1, X_train.shape[1])))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(500, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(250, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for LSTM\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_target_reshaped = X_target.reshape((X_target.shape[0], 1, X_target.shape[1]))\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train_reshaped, y_train, epochs=50, batch_size=16, verbose=1)\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=16,verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('model_am_task1.h5')\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_target_reshaped)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_inv = scaler_casos.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Set values less than 0 to 0\n",
    "y_pred_inv[y_pred_inv < 0] = 0\n",
    "# Convert the predictions to integers\n",
    "y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "# Inverse transform the actual values\n",
    "y_target_inv = scaler_casos.inverse_transform(target_data['casos_scaled'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# Print or return the real cases\n",
    "print(\"Real Cases (Actual):\", y_target_inv)\n",
    "print(\"Real Cases (Predicted):\", y_pred_inv)\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "mape = np.mean(np.abs((y_target_inv - y_pred_inv) / y_target_inv)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "\n",
    "# Create a DataFrame with the date, real cases, and predicted cases\n",
    "results_df = pd.DataFrame({\n",
    "    'date': target_pca_df.index,\n",
    "    'real': y_target_inv,\n",
    "    'predict': y_pred_inv\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('am(1).csv', index=False)\n",
    "\n",
    "print(\"Results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnTuaS8OPGzN",
    "outputId": "9a32c081-ecfd-4e5b-af77-f8acee1bfa27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in /usr/local/lib/python3.10/dist-packages (1.1.5)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.25.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from prophet) (3.7.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (2.0.3)\n",
      "Requirement already satisfied: holidays>=0.25 in /usr/local/lib/python3.10/dist-packages (from prophet) (0.51)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from prophet) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from prophet) (6.4.0)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.25->prophet) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.4->prophet) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->holidays>=0.25->prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf-A0J-iQv91",
    "outputId": "9663e911-c27f-4984-ed3f-ddb64eb8938d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-4ca4ad7767c6>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-9-4ca4ad7767c6>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/oymkmosf.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/1wv2cioq.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=48182', 'data', 'file=/tmp/tmpovx4b3gt/oymkmosf.json', 'init=/tmp/tmpovx4b3gt/1wv2cioq.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modeltmid5ag_/prophet_model-20240630174817.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:48:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:48:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Cases: [216, 186, 132, 133, 165, 161, 143, 142, 106, 74, 47, 65, 163, 127, 170, 226, 240, 246, 274, 354, 482, 577, 561, 614, 581, 444, 543, 509, 476, 636, 689, 666, 615, 512, 475, 514, 424, 362, 340, 339, 291, 253, 272, 216, 210, 224, 188, 134, 133, 104, 88]\n",
      "Predicted Cases: [0, 0, 0, 0, 161, 98, 123, 115, 186, 181, 0, 47, 79, 0, 240, 420, 460, 773, 651, 829, 961, 902, 1034, 1045, 1683, 1983, 2141, 2188, 2150, 2202, 2313, 2119, 1896, 1745, 1409, 1206, 929, 624, 629, 880, 544, 391, 440, 263, 11, 72, 161, 0, 0, 0, 0]\n",
      "Mean Absolute Error (MAE): 475.0980392156863\n",
      "Mean Absolute Percentage Error (MAPE): 121.94909027802944%\n",
      "Results saved to 'ce_task1_prophet_results_with_variance_threshold.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "\n",
    "# Load data\n",
    "dengue_file_path = 'aggregated_dengue_data_ce.csv'\n",
    "climate_file_path = 'aggregated_climate_data_ce.csv'\n",
    "dengue_data = pd.read_csv(dengue_file_path)\n",
    "climate_data = pd.read_csv(climate_file_path)\n",
    "\n",
    "# Filter for train_1 == True and target_1 == True\n",
    "dengue_data['train_1'] = dengue_data['train_1'].astype(bool)\n",
    "dengue_data['target_1'] = dengue_data['target_1'].astype(bool)\n",
    "\n",
    "dengue_train = dengue_data[dengue_data['train_1']]\n",
    "dengue_target = dengue_data[dengue_data['target_1']]\n",
    "\n",
    "# Convert date columns to datetime\n",
    "dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "# Merge the datasets on 'date'\n",
    "train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "# Select relevant columns excluding 'epiweek'\n",
    "columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                   'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                   'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                   'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                   'thermal_range', 'rainy_days']\n",
    "\n",
    "train_data = train_data[columns_to_keep]\n",
    "target_data = target_data[columns_to_keep]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "selected_feature_names = list(selected_feature_names)\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "# Add 'casos' and 'date' to the selected features\n",
    "selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "# Update train_data and target_data with selected features\n",
    "train_data = train_data[selected_feature_names]\n",
    "target_data = target_data[selected_feature_names]\n",
    "\n",
    "# Standardize the climate features\n",
    "scaler = StandardScaler()\n",
    "train_data[selected_feature_names[2:]] = scaler.fit_transform(train_data[selected_feature_names[2:]])\n",
    "target_data[selected_feature_names[2:]] = scaler.transform(target_data[selected_feature_names[2:]])\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "train_data.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "target_data.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "\n",
    "# Initialize the Prophet model\n",
    "model = Prophet()\n",
    "\n",
    "# Add climate features as regressors\n",
    "for feature in selected_feature_names[2:]:\n",
    "    model.add_regressor(feature)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_data)\n",
    "\n",
    "# Make future DataFrame\n",
    "future = model.make_future_dataframe(periods=len(target_data), freq='W')\n",
    "\n",
    "# Add the climate features to the future DataFrame\n",
    "future = future.merge(climate_data[['date'] + selected_feature_names[2:]], left_on='ds', right_on='date', how='left').drop(columns=['date'])\n",
    "\n",
    "# Ensure the climate features in the future DataFrame are standardized\n",
    "future[selected_feature_names[2:]] = scaler.transform(future[selected_feature_names[2:]])\n",
    "\n",
    "# Make predictions\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Extract the forecasted values for the target period\n",
    "y_pred_inv = forecast.loc[forecast['ds'].isin(target_data['ds']), 'yhat'].values\n",
    "\n",
    "# Ensure predicted values are non-negative integers\n",
    "y_pred_inv[y_pred_inv < 0] = 0\n",
    "y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "# Get the actual values\n",
    "y_target_inv = target_data['y'].values\n",
    "\n",
    "# Print or return the real cases\n",
    "print(\"Actual Cases:\", y_target_inv.tolist())\n",
    "print(\"Predicted Cases:\", y_pred_inv.tolist())\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "mape = mean_absolute_percentage_error(y_target_inv, y_pred_inv) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df = pd.DataFrame({\n",
    "    'date': target_data['ds'],\n",
    "    'real': y_target_inv,\n",
    "    'predict': y_pred_inv\n",
    "})\n",
    "\n",
    "results_df.to_csv('ce_task1_prophet_results_with_variance_threshold.csv', index=False)\n",
    "print(\"Results saved to 'ce_task1_prophet_results_with_variance_threshold.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfLu98uLRiGu",
    "outputId": "b2280db5-f044-494a-b90b-6f237b8b09bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-5a3953a74899>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-10-5a3953a74899>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/kxyayhfu.json\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/pp2p7vns.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=9871', 'data', 'file=/tmp/tmpovx4b3gt/kxyayhfu.json', 'init=/tmp/tmpovx4b3gt/pp2p7vns.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelbkfew3th/prophet_model-20240630175142.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:51:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:51:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Cases: [216, 186, 132, 133, 165, 161, 143, 142, 106, 74, 47, 65, 163, 127, 170, 226, 240, 246, 274, 354, 482, 577, 561, 614, 581, 444, 543, 509, 476, 636, 689, 666, 615, 512, 475, 514, 424, 362, 340, 339, 291, 253, 272, 216, 210, 224, 188, 134, 133, 104, 88]\n",
      "Predicted Cases: [0, 0, 0, 0, 30, 38, 0, 0, 120, 108, 0, 0, 60, 41, 87, 394, 340, 532, 538, 662, 934, 873, 849, 1079, 1620, 1804, 2059, 2180, 2171, 2327, 2501, 2171, 1930, 1749, 1433, 1203, 996, 747, 765, 915, 461, 544, 475, 205, 91, 224, 205, 0, 0, 0, 29]\n",
      "Mean Absolute Error (MAE): 469.72549019607845\n",
      "Mean Absolute Percentage Error (MAPE): 119.6404358980268%\n",
      "Results saved to 'ce_task1_prophet_results_with_pca.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "dengue_file_path = 'aggregated_dengue_data_ce.csv'\n",
    "climate_file_path = 'aggregated_climate_data_ce.csv'\n",
    "dengue_data = pd.read_csv(dengue_file_path)\n",
    "climate_data = pd.read_csv(climate_file_path)\n",
    "\n",
    "# Filter for train_1 == True and target_1 == True\n",
    "dengue_data['train_1'] = dengue_data['train_1'].astype(bool)\n",
    "dengue_data['target_1'] = dengue_data['target_1'].astype(bool)\n",
    "\n",
    "dengue_train = dengue_data[dengue_data['train_1']]\n",
    "dengue_target = dengue_data[dengue_data['target_1']]\n",
    "\n",
    "# Convert date columns to datetime\n",
    "dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "# Merge the datasets on 'date'\n",
    "train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "# Select relevant columns excluding 'epiweek'\n",
    "columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                   'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                   'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                   'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                   'thermal_range', 'rainy_days']\n",
    "\n",
    "train_data = train_data[columns_to_keep]\n",
    "target_data = target_data[columns_to_keep]\n",
    "\n",
    "# Apply Variance Threshold\n",
    "climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "selected_feature_names = list(selected_feature_names)\n",
    "print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "# Add 'casos' and 'date' to the selected features\n",
    "selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "# Update train_data and target_data with selected features\n",
    "train_data = train_data[selected_feature_names]\n",
    "target_data = target_data[selected_feature_names]\n",
    "\n",
    "# Standardize the climate features\n",
    "scaler = StandardScaler()\n",
    "train_data[selected_feature_names[2:]] = scaler.fit_transform(train_data[selected_feature_names[2:]])\n",
    "target_data[selected_feature_names[2:]] = scaler.transform(target_data[selected_feature_names[2:]])\n",
    "\n",
    "# Ensure no NaN values in the climate features before applying PCA\n",
    "train_data.dropna(inplace=True)\n",
    "target_data.dropna(inplace=True)\n",
    "\n",
    "# Apply PCA to climate features\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(train_data[selected_feature_names[2:]])\n",
    "X_target_pca = pca.transform(target_data[selected_feature_names[2:]])\n",
    "\n",
    "# Create DataFrames with PCA components\n",
    "n_components = X_train_pca.shape[1]\n",
    "train_pca_df = pd.DataFrame(X_train_pca, index=train_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "target_pca_df = pd.DataFrame(X_target_pca, index=target_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Add the scaled target variable 'casos_scaled' and 'date' to the PCA DataFrames\n",
    "train_pca_df['casos'] = train_data['casos'].values\n",
    "train_pca_df['date'] = train_data['date'].values\n",
    "target_pca_df['casos'] = target_data['casos'].values\n",
    "target_pca_df['date'] = target_data['date'].values\n",
    "\n",
    "# Ensure no NaN values after PCA\n",
    "train_pca_df.dropna(inplace=True)\n",
    "target_pca_df.dropna(inplace=True)\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "train_pca_df.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "target_pca_df.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "\n",
    "# Initialize the Prophet model\n",
    "model = Prophet()\n",
    "\n",
    "# Add PCA components as regressors\n",
    "for feature in train_pca_df.columns:\n",
    "    if feature not in ['ds', 'y']:\n",
    "        model.add_regressor(feature)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_pca_df)\n",
    "\n",
    "# Save the model\n",
    "with open('prophet_model_ce_task1_with_pca.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Make future DataFrame\n",
    "future = model.make_future_dataframe(periods=len(target_pca_df), freq='W')\n",
    "\n",
    "# Add PCA components to the future DataFrame\n",
    "future = future.merge(target_pca_df.drop(columns=['y']), on='ds', how='left')\n",
    "\n",
    "# Ensure no NaN values in the future DataFrame\n",
    "future.dropna(inplace=True)\n",
    "\n",
    "# Make predictions\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Extract the forecasted values for the target period\n",
    "y_pred_inv = forecast.loc[forecast['ds'].isin(target_pca_df['ds']), 'yhat'].values\n",
    "\n",
    "# Ensure predicted values are non-negative integers\n",
    "y_pred_inv[y_pred_inv < 0] = 0\n",
    "y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "# Get the actual values\n",
    "y_target_inv = target_pca_df['y'].values\n",
    "\n",
    "# Print or return the real cases\n",
    "print(\"Actual Cases:\", y_target_inv.tolist())\n",
    "print(\"Predicted Cases:\", y_pred_inv.tolist())\n",
    "\n",
    "# Calculate MAE and MAPE\n",
    "mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "mape = mean_absolute_percentage_error(y_target_inv, y_pred_inv) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df = pd.DataFrame({\n",
    "    'date': target_pca_df['ds'],\n",
    "    'real': y_target_inv,\n",
    "    'predict': y_pred_inv\n",
    "})\n",
    "\n",
    "results_df.to_csv('ce_task1_prophet_results_with_pca.csv', index=False)\n",
    "print(\"Results saved to 'ce_task1_prophet_results_with_pca.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWrMLECISEv-",
    "outputId": "03f3ff1f-a4ae-4fb9-c8a5-6e24f37fab76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM - Selected Features for train_1 and target_1: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/fh2j6r8y.json\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/khrl1t4b.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=16560', 'data', 'file=/tmp/tmpovx4b3gt/fh2j6r8y.json', 'init=/tmp/tmpovx4b3gt/khrl1t4b.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelpt9qded1/prophet_model-20240630175404.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM - Actual Cases for train_1 and target_1: [250, 196, 161, 147, 129, 117, 118, 110, 87, 52, 44, 81, 198, 195, 198, 214, 251, 277, 180, 148, 167, 143, 125, 119, 122, 125, 106, 153, 135, 143, 127, 131, 89, 65, 75, 69, 78, 90, 103, 115, 93, 89, 57, 46, 75, 65, 67, 77, 75, 73, 57]\n",
      "AM - Predicted Cases for train_1 and target_1: [0, 0, 0, 131, 15, 0, 26, 80, 85, 54, 57, 50, 159, 260, 394, 441, 491, 550, 600, 688, 631, 563, 512, 474, 274, 277, 180, 98, 79, 16, 43, 0, 0, 0, 0, 155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "AM - Mean Absolute Error (MAE) for train_1 and target_1: 136.35294117647058\n",
      "AM - Mean Absolute Percentage Error (MAPE) for train_1 and target_1: 107.42845301692616%\n",
      "Results saved to 'am_train_1_target_1_prophet_results_with_pca.csv'\n",
      "AM - Selected Features for train_2 and target_2: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "<ipython-input-11-5d2b870abb01>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[selected_feature_names[2:]] = scaler.fit_transform(train_data[selected_feature_names[2:]])\n",
      "<ipython-input-11-5d2b870abb01>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data[selected_feature_names[2:]] = scaler.transform(target_data[selected_feature_names[2:]])\n",
      "<ipython-input-11-5d2b870abb01>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.dropna(inplace=True)\n",
      "<ipython-input-11-5d2b870abb01>:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_data.dropna(inplace=True)\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/cmxn3oo0.json\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/lu6cyw2w.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=45633', 'data', 'file=/tmp/tmpovx4b3gt/cmxn3oo0.json', 'init=/tmp/tmpovx4b3gt/lu6cyw2w.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modeluuow83bh/prophet_model-20240630175405.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/3v9aa5mt.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM - Actual Cases for train_2 and target_2: [55, 73, 82, 62, 115, 114, 153, 156, 204, 300, 313, 256, 597, 523, 690, 507, 602, 615, 607, 616, 663, 625, 506, 401, 259, 309, 213, 203, 176, 154, 175, 156, 191, 138, 36]\n",
      "AM - Predicted Cases for train_2 and target_2: [0, 0, 0, 0, 0, 0, 0, 49, 64, 0, 0, 0, 125, 124, 227, 262, 331, 387, 468, 576, 553, 478, 324, 276, 251, 156, 76, 22, 8, 0, 0, 0, 0, 85, 0]\n",
      "AM - Mean Absolute Error (MAE) for train_2 and target_2: 171.5142857142857\n",
      "AM - Mean Absolute Percentage Error (MAPE) for train_2 and target_2: 70.47642106768838%\n",
      "Results saved to 'am_train_2_target_2_prophet_results_with_pca.csv'\n",
      "CE - Selected Features for train_1 and target_1: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/8_z3flg1.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=53094', 'data', 'file=/tmp/tmpovx4b3gt/3v9aa5mt.json', 'init=/tmp/tmpovx4b3gt/8_z3flg1.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelyr8fvs0w/prophet_model-20240630175406.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/ni8jzj3f.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Actual Cases for train_1 and target_1: [216, 186, 132, 133, 165, 161, 143, 142, 106, 74, 47, 65, 163, 127, 170, 226, 240, 246, 274, 354, 482, 577, 561, 614, 581, 444, 543, 509, 476, 636, 689, 666, 615, 512, 475, 514, 424, 362, 340, 339, 291, 253, 272, 216, 210, 224, 188, 134, 133, 104, 88]\n",
      "CE - Predicted Cases for train_1 and target_1: [0, 0, 0, 0, 30, 38, 0, 0, 120, 108, 0, 0, 60, 41, 87, 394, 340, 532, 538, 662, 934, 873, 849, 1079, 1620, 1804, 2059, 2180, 2171, 2327, 2501, 2171, 1930, 1749, 1433, 1203, 996, 747, 765, 915, 461, 544, 475, 205, 91, 224, 205, 0, 0, 0, 29]\n",
      "CE - Mean Absolute Error (MAE) for train_1 and target_1: 469.72549019607845\n",
      "CE - Mean Absolute Percentage Error (MAPE) for train_1 and target_1: 119.6404358980268%\n",
      "Results saved to 'ce_train_1_target_1_prophet_results_with_pca.csv'\n",
      "CE - Selected Features for train_2 and target_2: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/epuhv1zi.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=44781', 'data', 'file=/tmp/tmpovx4b3gt/ni8jzj3f.json', 'init=/tmp/tmpovx4b3gt/epuhv1zi.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_model2acziuff/prophet_model-20240630175407.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/rdwi26wz.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE - Actual Cases for train_2 and target_2: [85, 88, 86, 61, 78, 63, 84, 75, 81, 64, 26, 28, 77, 74, 104, 124, 170, 181, 261, 358, 451, 543, 522, 535, 510, 927, 1045, 1022, 800, 874, 781, 706, 636, 398, 92]\n",
      "CE - Predicted Cases for train_2 and target_2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 112, 261, 149, 370, 413, 476, 789, 870, 1279, 1365, 1326, 1633, 1672, 1842, 1880, 1617, 1235, 952]\n",
      "CE - Mean Absolute Error (MAE) for train_2 and target_2: 285.34285714285716\n",
      "CE - Mean Absolute Percentage Error (MAPE) for train_2 and target_2: 109.46019111611605%\n",
      "Results saved to 'ce_train_2_target_2_prophet_results_with_pca.csv'\n",
      "GO - Selected Features for train_1 and target_1: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/ru3ysdae.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=74620', 'data', 'file=/tmp/tmpovx4b3gt/rdwi26wz.json', 'init=/tmp/tmpovx4b3gt/ru3ysdae.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelf7t4i6vg/prophet_model-20240630175407.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/1wwlyzdh.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Actual Cases for train_1 and target_1: [921, 867, 762, 649, 949, 959, 921, 923, 842, 680, 327, 527, 1532, 1554, 1785, 1596, 2097, 2116, 1867, 1863, 2230, 2320, 2423, 3044, 2970, 2275, 2847, 2611, 2396, 2599, 2382, 2105, 1511, 1360, 1077, 1077, 868, 727, 622, 616, 577, 527, 599, 567, 689, 627, 683, 676, 820, 869, 735]\n",
      "GO - Predicted Cases for train_1 and target_1: [1396, 1240, 1427, 795, 1051, 1497, 1523, 1818, 1800, 1634, 1503, 1995, 2593, 3501, 4152, 4546, 4678, 4981, 5236, 5348, 5608, 5635, 5676, 5804, 5955, 5792, 5816, 5565, 5651, 5634, 5392, 4179, 3801, 3448, 2516, 3149, 2115, 2132, 1332, 2073, 2075, 1994, 1611, 1847, 2004, 2234, 2028, 1995, 1701, 1754, 2249]\n",
      "GO - Mean Absolute Error (MAE) for train_1 and target_1: 1810.0588235294117\n",
      "GO - Mean Absolute Percentage Error (MAPE) for train_1 and target_1: 145.8616750277819%\n",
      "Results saved to 'go_train_1_target_1_prophet_results_with_pca.csv'\n",
      "GO - Selected Features for train_2 and target_2: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/v3x0gb_q.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=47386', 'data', 'file=/tmp/tmpovx4b3gt/1wwlyzdh.json', 'init=/tmp/tmpovx4b3gt/v3x0gb_q.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelw5644grz/prophet_model-20240630175408.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/9stljqxe.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO - Actual Cases for train_2 and target_2: [680, 816, 769, 769, 1053, 951, 1170, 1332, 1198, 993, 706, 1203, 3670, 4130, 5047, 7407, 12026, 14054, 15860, 18418, 19220, 18801, 19955, 19246, 15382, 18510, 18228, 17791, 15690, 15194, 13294, 10570, 6865, 3712, 878]\n",
      "GO - Predicted Cases for train_2 and target_2: [826, 556, 741, 954, 317, 1363, 1187, 1114, 1266, 925, 924, 1355, 1460, 2480, 3169, 3383, 3538, 3624, 3876, 4246, 4481, 4604, 4805, 5037, 4676, 4760, 4516, 4408, 4430, 4565, 4383, 4006, 3205, 2398, 1944]\n",
      "GO - Mean Absolute Error (MAE) for train_2 and target_2: 6016.971428571429\n",
      "GO - Mean Absolute Percentage Error (MAPE) for train_2 and target_2: 52.4106163269499%\n",
      "Results saved to 'go_train_2_target_2_prophet_results_with_pca.csv'\n",
      "MG - Selected Features for train_1 and target_1: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/_qpps0hk.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=70461', 'data', 'file=/tmp/tmpovx4b3gt/9stljqxe.json', 'init=/tmp/tmpovx4b3gt/_qpps0hk.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelr7ug4qht/prophet_model-20240630175408.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/8erk8scy.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MG - Actual Cases for train_1 and target_1: [417, 464, 467, 357, 320, 325, 405, 383, 368, 367, 253, 764, 2403, 3149, 4424, 5348, 8307, 10747, 11147, 12762, 16314, 19615, 22052, 24680, 25995, 25014, 28928, 25885, 22023, 22246, 20156, 16231, 10976, 8363, 6261, 5239, 3907, 2582, 1895, 1506, 1336, 1126, 1027, 1020, 928, 875, 839, 707, 959, 1046, 1004]\n",
      "MG - Predicted Cases for train_1 and target_1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1081, 1659, 2658, 2430, 4384, 5637, 6226, 7594, 8051, 8378, 9425, 11091, 11449, 12263, 10861, 10275, 9204, 7853, 2927, 2037, 1237, 0, 1134, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1197, 136, 0, 0, 0, 734]\n",
      "MG - Mean Absolute Error (MAE) for train_1 and target_1: 4796.764705882353\n",
      "MG - Mean Absolute Percentage Error (MAPE) for train_1 and target_1: 80.78377379670346%\n",
      "Results saved to 'mg_train_1_target_1_prophet_results_with_pca.csv'\n",
      "MG - Selected Features for train_2 and target_2: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/c1yv81di.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63665', 'data', 'file=/tmp/tmpovx4b3gt/8erk8scy.json', 'init=/tmp/tmpovx4b3gt/c1yv81di.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelee4dltkl/prophet_model-20240630175409.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/5cy7d_f1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MG - Actual Cases for train_2 and target_2: [1203, 1547, 1730, 1916, 2909, 3005, 4349, 4991, 5462, 6082, 4753, 5561, 18338, 24030, 37131, 56826, 78217, 91237, 103421, 128992, 133971, 128460, 127278, 127571, 94695, 96086, 85020, 65214, 50304, 41826, 33398, 23354, 14446, 5778, 1314]\n",
      "MG - Predicted Cases for train_2 and target_2: [2688, 1225, 1829, 2950, 0, 4006, 2900, 1849, 2484, 1171, 1491, 3307, 1581, 4233, 5313, 4962, 5605, 6296, 7736, 9676, 11441, 12400, 13753, 15211, 14320, 15847, 15465, 14927, 14051, 13609, 12573, 11028, 8019, 4905, 3095]\n",
      "MG - Mean Absolute Error (MAE) for train_2 and target_2: 39121.97142857143\n",
      "MG - Mean Absolute Percentage Error (MAPE) for train_2 and target_2: 72.45200873644005%\n",
      "Results saved to 'mg_train_2_target_2_prophet_results_with_pca.csv'\n",
      "PR - Selected Features for train_1 and target_1: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/4ooxe_12.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=68630', 'data', 'file=/tmp/tmpovx4b3gt/5cy7d_f1.json', 'init=/tmp/tmpovx4b3gt/4ooxe_12.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_modelobal_awi/prophet_model-20240630175409.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "<ipython-input-11-5d2b870abb01>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
      "<ipython-input-11-5d2b870abb01>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/fj0kek04.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR - Actual Cases for train_1 and target_1: [266, 366, 422, 439, 563, 680, 777, 791, 933, 1096, 939, 553, 440, 457, 574, 742, 1050, 1588, 2332, 2645, 4357, 6350, 8200, 12578, 15598, 16812, 20908, 19158, 15635, 16117, 15109, 11907, 7831, 5781, 4243, 2870, 1759, 1499, 1220, 878, 643, 579, 555, 508, 489, 488, 378, 354, 459, 488, 503]\n",
      "PR - Predicted Cases for train_1 and target_1: [1312, 1733, 1831, 1902, 1741, 1956, 1821, 1837, 2074, 2103, 1789, 1885, 2385, 2464, 2972, 3526, 4140, 4247, 5238, 5264, 5686, 5935, 6013, 6642, 6279, 6524, 6211, 6390, 5570, 5097, 4614, 4395, 2955, 2338, 2519, 2007, 2183, 2095, 1684, 1538, 1346, 1252, 2062, 1262, 1579, 1354, 1548, 1576, 1956, 1336, 1220]\n",
      "PR - Mean Absolute Error (MAE) for train_1 and target_1: 3033.235294117647\n",
      "PR - Mean Absolute Percentage Error (MAPE) for train_1 and target_1: 163.70994386980908%\n",
      "Results saved to 'pr_train_1_target_1_prophet_results_with_pca.csv'\n",
      "PR - Selected Features for train_2 and target_2: ['temp_min', 'temp_med', 'temp_max', 'precip_max', 'precip_tot', 'rel_humid_min', 'rel_humid_med', 'rel_humid_max', 'thermal_range', 'rainy_days']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:input tempfile: /tmp/tmpovx4b3gt/sm2rijis.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41300', 'data', 'file=/tmp/tmpovx4b3gt/fj0kek04.json', 'init=/tmp/tmpovx4b3gt/sm2rijis.json', 'output', 'file=/tmp/tmpovx4b3gt/prophet_model6d3x_kvn/prophet_model-20240630175410.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "17:54:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "17:54:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR - Actual Cases for train_2 and target_2: [529, 665, 586, 676, 1027, 1078, 1397, 1473, 2042, 3172, 2582, 2699, 5545, 7182, 9889, 12103, 12548, 15697, 21029, 25552, 27678, 33914, 39538, 44870, 42881, 46870, 45503, 44865, 35280, 36298, 36830, 30880, 19300, 10021, 3162]\n",
      "PR - Predicted Cases for train_2 and target_2: [2415, 2054, 2381, 2550, 2658, 2025, 2219, 2545, 2878, 3009, 2534, 2629, 2698, 2932, 3406, 3660, 4282, 4497, 4981, 5704, 6211, 6518, 7247, 7322, 7541, 8016, 7687, 7909, 7233, 6472, 5970, 4765, 4460, 3653, 3320]\n",
      "PR - Mean Absolute Error (MAE) for train_2 and target_2: 14108.57142857143\n",
      "PR - Mean Absolute Percentage Error (MAPE) for train_2 and target_2: 92.70668217480778%\n",
      "Results saved to 'pr_train_2_target_2_prophet_results_with_pca.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from prophet import Prophet\n",
    "import pickle\n",
    "\n",
    "# List of states and their corresponding file paths\n",
    "states = ['am', 'ce', 'go', 'mg', 'pr']\n",
    "tasks = [('train_1', 'target_1'), ('train_2', 'target_2')]\n",
    "\n",
    "for state in states:\n",
    "    for train_col, target_col in tasks:\n",
    "        # Load data\n",
    "        dengue_file_path = f'aggregated_dengue_data_{state}.csv'\n",
    "        climate_file_path = f'aggregated_climate_data_{state}.csv'\n",
    "        dengue_data = pd.read_csv(dengue_file_path)\n",
    "        climate_data = pd.read_csv(climate_file_path)\n",
    "\n",
    "        # Filter for train and target columns\n",
    "        dengue_data[train_col] = dengue_data[train_col].astype(bool)\n",
    "        dengue_data[target_col] = dengue_data[target_col].astype(bool)\n",
    "\n",
    "        dengue_train = dengue_data[dengue_data[train_col]]\n",
    "        dengue_target = dengue_data[dengue_data[target_col]]\n",
    "\n",
    "        # Convert date columns to datetime\n",
    "        dengue_train['date'] = pd.to_datetime(dengue_train['date'])\n",
    "        dengue_target['date'] = pd.to_datetime(dengue_target['date'])\n",
    "        climate_data['date'] = pd.to_datetime(climate_data['date'])\n",
    "\n",
    "        # Merge the datasets on 'date'\n",
    "        train_data = pd.merge(dengue_train, climate_data, on='date')\n",
    "        target_data = pd.merge(dengue_target, climate_data, on='date')\n",
    "\n",
    "        # Select relevant columns excluding 'epiweek'\n",
    "        columns_to_keep = ['date', 'casos', 'temp_min', 'temp_med', 'temp_max',\n",
    "                           'precip_min', 'precip_med', 'precip_max', 'precip_tot',\n",
    "                           'pressure_min', 'pressure_med', 'pressure_max',\n",
    "                           'rel_humid_min', 'rel_humid_med', 'rel_humid_max',\n",
    "                           'thermal_range', 'rainy_days']\n",
    "\n",
    "        train_data = train_data[columns_to_keep]\n",
    "        target_data = target_data[columns_to_keep]\n",
    "\n",
    "        # Apply Variance Threshold\n",
    "        climate_features = train_data.drop(columns=['casos', 'date'])\n",
    "        selector = VarianceThreshold(threshold=0.1)\n",
    "        selected_features = selector.fit_transform(climate_features)\n",
    "\n",
    "        # Get the selected feature names\n",
    "        selected_feature_names = climate_features.columns[selector.get_support()]\n",
    "        selected_feature_names = list(selected_feature_names)\n",
    "        print(f\"{state.upper()} - Selected Features for {train_col} and {target_col}: {selected_feature_names}\")\n",
    "\n",
    "        # Add 'casos' and 'date' to the selected features\n",
    "        selected_feature_names = ['casos', 'date'] + selected_feature_names\n",
    "\n",
    "        # Update train_data and target_data with selected features\n",
    "        train_data = train_data[selected_feature_names]\n",
    "        target_data = target_data[selected_feature_names]\n",
    "\n",
    "        # Standardize the climate features\n",
    "        scaler = StandardScaler()\n",
    "        train_data[selected_feature_names[2:]] = scaler.fit_transform(train_data[selected_feature_names[2:]])\n",
    "        target_data[selected_feature_names[2:]] = scaler.transform(target_data[selected_feature_names[2:]])\n",
    "\n",
    "        # Ensure no NaN values in the climate features before applying PCA\n",
    "        train_data.dropna(inplace=True)\n",
    "        target_data.dropna(inplace=True)\n",
    "\n",
    "        # Apply PCA to climate features\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X_train_pca = pca.fit_transform(train_data[selected_feature_names[2:]])\n",
    "        X_target_pca = pca.transform(target_data[selected_feature_names[2:]])\n",
    "\n",
    "        # Create DataFrames with PCA components\n",
    "        n_components = X_train_pca.shape[1]\n",
    "        train_pca_df = pd.DataFrame(X_train_pca, index=train_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "        target_pca_df = pd.DataFrame(X_target_pca, index=target_data.index, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "\n",
    "        # Add the scaled target variable 'casos' and 'date' to the PCA DataFrames\n",
    "        train_pca_df['casos'] = train_data['casos'].values\n",
    "        train_pca_df['date'] = train_data['date'].values\n",
    "        target_pca_df['casos'] = target_data['casos'].values\n",
    "        target_pca_df['date'] = target_data['date'].values\n",
    "\n",
    "        # Ensure no NaN values after PCA\n",
    "        train_pca_df.dropna(inplace=True)\n",
    "        target_pca_df.dropna(inplace=True)\n",
    "\n",
    "        # Prepare the data for Prophet\n",
    "        train_pca_df.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "        target_pca_df.rename(columns={'date': 'ds', 'casos': 'y'}, inplace=True)\n",
    "\n",
    "        # Initialize the Prophet model\n",
    "        model = Prophet()\n",
    "\n",
    "        # Add PCA components as regressors\n",
    "        for feature in train_pca_df.columns:\n",
    "            if feature not in ['ds', 'y']:\n",
    "                model.add_regressor(feature)\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(train_pca_df)\n",
    "\n",
    "        # Save the model\n",
    "        model_filename = f'prophet_model_{state}_{train_col}_{target_col}_with_pca.pkl'\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        # Make future DataFrame\n",
    "        future = model.make_future_dataframe(periods=len(target_pca_df), freq='W')\n",
    "\n",
    "        # Add PCA components to the future DataFrame\n",
    "        future = future.merge(target_pca_df.drop(columns=['y']), on='ds', how='left')\n",
    "\n",
    "        # Ensure no NaN values in the future DataFrame\n",
    "        future.dropna(inplace=True)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Extract the forecasted values for the target period\n",
    "        y_pred_inv = forecast.loc[forecast['ds'].isin(target_pca_df['ds']), 'yhat'].values\n",
    "\n",
    "        # Ensure predicted values are non-negative integers\n",
    "        y_pred_inv[y_pred_inv < 0] = 0\n",
    "        y_pred_inv = y_pred_inv.astype(int)\n",
    "\n",
    "        # Get the actual values\n",
    "        y_target_inv = target_pca_df['y'].values\n",
    "\n",
    "        # Print or return the real cases\n",
    "        print(f\"{state.upper()} - Actual Cases for {train_col} and {target_col}: {y_target_inv.tolist()}\")\n",
    "        print(f\"{state.upper()} - Predicted Cases for {train_col} and {target_col}: {y_pred_inv.tolist()}\")\n",
    "\n",
    "        # Calculate MAE and MAPE\n",
    "        mae = mean_absolute_error(y_target_inv, y_pred_inv)\n",
    "        mape = mean_absolute_percentage_error(y_target_inv, y_pred_inv) * 100\n",
    "\n",
    "        print(f\"{state.upper()} - Mean Absolute Error (MAE) for {train_col} and {target_col}: {mae}\")\n",
    "        print(f\"{state.upper()} - Mean Absolute Percentage Error (MAPE) for {train_col} and {target_col}: {mape}%\")\n",
    "\n",
    "        # Save the results to a CSV file\n",
    "        results_filename = f'{state}_{train_col}_{target_col}_prophet_results_with_pca.csv'\n",
    "        results_df = pd.DataFrame({\n",
    "            'date': target_pca_df['ds'],\n",
    "            'real': y_target_inv,\n",
    "            'predict': y_pred_inv\n",
    "        })\n",
    "        results_df.to_csv(results_filename, index=False)\n",
    "        print(f\"Results saved to '{results_filename}'\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
